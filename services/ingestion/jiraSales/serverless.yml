service: jiraSalesWebhook

dataplattform:
  dependencies:
    - ../../infrastructure/deploymentBucket
    - ../../infrastructure/datalake
    - ../../infrastructure/events
    - ../../infrastructure/monitoring
    - ../../infrastructure/glue
    - ../../infrastructure/ingestApiGateway
  glue:
    tableName: jira_sales
    accessLevel: 2

custom:
  editable:
    timeout: 12
    webhookIngestHandlerFile: jira_webhook_ingest_lambda
    pollerIngestHandlerFile: jira_poller_ingest_lambda
    processHandlerFile: jira_process_lambda
    databaseName: level_2
    description: Endpoint for Jira webhooks and poller of historical data
    accessLevel: level-2
    dataFolder: jira/sales
    scheduleRate: cron(0 8 1 1 ? *) # cron(minute hour day-of-month month day-of-week year)

  project: dataplattform
  stage: ${opt:stage, self:provider.stage}
  service: ${self:custom.stage}-${self:service}
  accessPath: data/${self:custom.editable.accessLevel}/${self:custom.editable.dataFolder}/
  sqsQueueName: ${self:custom.stage}-${self:service}-sqs.fifo
  sqsQueueDLName: ${self:custom.stage}-${self:service}-sqs-dl.fifo
  pythonRequirements:
    dockerizePip: non-linux
    noDeploy:
      - boto3
      - botocore

provider:
  name: aws
  stage: dev
  region: eu-central-1
  stackName: ${self:custom.stage}-${self:service}
  deploymentBucket:
    name: |-
      ${self:custom.stage}-${file(../../infrastructure/deploymentBucket/config.yml):bucketName,
      file(../../infrastructure/deploymentBucket/serverless.yml):defaultBucketName}
  runtime: python3.7
  memorySize: 1024
  timeout: ${self:custom.editable.timeout}

  # imports api gateway resources exported by ingestApiGateway service
  apiGateway:
    restApiId:
      'Fn::ImportValue': ${self:custom.stage}-ingestApiGateway-restApiId
    restApiRootResourceId:
      'Fn::ImportValue': ${self:custom.stage}-ingestApiGateway-rootResourceId

  tags:
    project: ${self:custom.project}
    layer: ingestion
    ingestion: webHooks
  stackTags:
    project: ${self:custom.project}
    layer: ingestion
    ingestion: webHooks

  tracing:
    apiGateway: true
    lambda: true

package:
  individually: true
  exclude:
    - "./**"

functions:
  pollerIngest:
    handler: ${self:custom.editable.pollerIngestHandlerFile}.handler
    name: ${self:custom.stage}-${self:service}-poller-ingest
    description: ${self:custom.editable.description}
    role: !GetAtt IngestLambdaRole.Arn
    package:
      include:
        - '*.py'
    environment:
      STAGE: ${self:custom.stage}
      SERVICE: ${self:service}
      DATALAKE: !ImportValue ${self:custom.stage}-datalakeName
      ACCESS_PATH: ${self:custom.accessPath}
      DEFAULT_DATABASE: ${self:custom.editable.databaseName}
      SQS_QUEUE_NAME: ${self:custom.sqsQueueName}
      SQS_MESSAGE_GROUP_ID: ${self:custom.sqsQueueName}-group1
    events:
      - schedule:
          name: ${self:custom.stage}-${self:service}-timer
          description: ${self:custom.editable.description}
          rate: ${self:custom.editable.scheduleRate}
          enabled: true
  webhookIngest:
    handler: ${self:custom.editable.webhookIngestHandlerFile}.handler
    name: ${self:custom.stage}-${self:service}-webhook-ingest
    description: ${self:custom.editable.description}
    role: !GetAtt IngestLambdaRole.Arn
    package:
      include:
        - '*.py'
    environment:
      STAGE: ${self:custom.stage}
      SERVICE: ${self:service}
      DATALAKE: !ImportValue ${self:custom.stage}-datalakeName
      ACCESS_PATH: ${self:custom.accessPath}
      DEFAULT_DATABASE: ${self:custom.editable.databaseName}
      SQS_QUEUE_NAME: ${self:custom.sqsQueueName}
      SQS_MESSAGE_GROUP_ID: ${self:custom.sqsQueueName}-group1
    events:
      - http:
          path: jira-sales-webhook/{secret}
          method: post
          private: false # if true API key is needed

  process:
    handler: ${self:custom.editable.processHandlerFile}.handler
    events:
      - sqs:
          arn:
            Fn::GetAtt:
              - EventQueue
              - Arn
          batchSize: 1

    name: ${self:custom.stage}-${self:service}-process
    description: ${self:custom.editable.description}
    role: !GetAtt ProcessLambdaRole.Arn
    package:
      include:
        - '*.py'
    environment:
      STAGE: ${self:custom.stage}
      SERVICE: ${self:service}
      DATALAKE: !ImportValue ${self:custom.stage}-datalakeName
      ACCESS_PATH: ${self:custom.accessPath}
      DEFAULT_DATABASE: ${self:custom.editable.databaseName}
      DATA_UPDATE_TOPIC: !ImportValue ${self:custom.stage}-data-update-topic-arn
      ACCESS_LEVEL: ${self:custom.editable.accessLevel}

resources:
  Resources:
    IngestLambdaRole:
      Type: AWS::IAM::Role
      Properties:
        RoleName: ${self:custom.stage}-${self:service}-ingest-role
        AssumeRolePolicyDocument:
          Version: "2012-10-17"
          Statement:
            - Effect: Allow
              Principal:
                Service:
                  - lambda.amazonaws.com
              Action: sts:AssumeRole
        ManagedPolicyArns:
          - "arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"
          - !ImportValue ${self:custom.stage}-lambda-xray-tracing
        Policies:
          - PolicyName: ${self:custom.stage}-DatalakeIO-${self:service}
            PolicyDocument:
              Version: "2012-10-17"
              Statement:
                - Effect: Allow
                  Action:
                    - s3:PutObject
                    - s3:ListObjects*
                    - s3:GetObject
                    - s3:CopyObject
                    - s3:DeleteObjects
                  Resource:
                    - Fn::Join:
                        - ""
                        - - !ImportValue ${self:custom.stage}-datalakeArn
                          - /${self:custom.accessPath}*
          - PolicyName: ${self:custom.stage}-${self:service}-ingest-sqsRole
            PolicyDocument:
              Version: "2012-10-17"
              Statement:
                - Effect: Allow
                  Action:
                    - sqs:GetQueueUrl
                    - sqs:SendMessageBatch
                    - sqs:SendMessage
                  Resource: !GetAtt EventQueue.Arn
          - PolicyName: ${self:custom.stage}-ParameterStore-${self:service}
            PolicyDocument:
              Version: '2012-10-17'
              Statement:
                - Effect: Allow
                  Action:
                    - 'ssm:GetParameter*'
                  Resource:
                    !Sub 'arn:aws:ssm:#{AWS::Region}:#{AWS::AccountId}:parameter/${self:custom.stage}/${self:service}/*'
    ProcessLambdaRole:
      Type: AWS::IAM::Role
      Properties:
        RoleName: ${self:custom.stage}-${self:service}-${self:custom.editable.processHandlerFile}-role
        AssumeRolePolicyDocument:
          Version: "2012-10-17"
          Statement:
            - Effect: Allow
              Principal:
                Service:
                  - lambda.amazonaws.com
              Action: sts:AssumeRole
        ManagedPolicyArns:
          - "arn:aws:iam::aws:policy/service-role/AWSLambdaSQSQueueExecutionRole"
          - !ImportValue ${self:custom.stage}-process-lambda-topic-access-role
          - !ImportValue ${self:custom.stage}-lambda-xray-tracing
        Policies:
          - PolicyName: ${self:custom.stage}-DatalakeIO-${self:service}
            PolicyDocument:
              Version: "2012-10-17"
              Statement:
                - Effect: Allow
                  Action:
                    - s3:PutObject
                    - s3:ListObjects*
                    - s3:GetObject
                    - s3:CopyObject
                    - s3:DeleteObjects
                  Resource:
                    - Fn::Join:
                        - ""
                        - - !ImportValue ${self:custom.stage}-datalakeArn
                          - /${self:custom.accessPath}*
          - PolicyName: ${self:custom.stage}-DatalakeBucket-${self:service}
            PolicyDocument:
              Version: "2012-10-17"
              Statement:
                - Effect: Allow
                  Action:
                    - s3:ListBucket
                    - s3:GetBucketLocation
                  Resource:
                    - Fn::Join:
                        - ""
                        - - !ImportValue ${self:custom.stage}-datalakeArn
                          - '*'
          - PolicyName: ${self:custom.stage}-glue-${self:service}-role
            PolicyDocument:
              Version: "2012-10-17"
              Statement:
                - Effect: Allow
                  Action:
                    - glue:GetCrawler
                    - glue:UpdateCrawler
                  Resource:
                    - !Sub 'arn:aws:glue:#{AWS::Region}:#{AWS::AccountId}:catalog'
                    - !Sub 'arn:aws:glue:#{AWS::Region}:#{AWS::AccountId}:database/${self:custom.stage}_*'
                    - !Sub 'arn:aws:glue:#{AWS::Region}:#{AWS::AccountId}:table/${self:custom.stage}_*'
                    - !Sub 'arn:aws:glue:#{AWS::Region}:#{AWS::AccountId}:crawler/${self:custom.stage}_*'
    EventQueue:
      Type: AWS::SQS::Queue
      Properties:
        FifoQueue: true
        QueueName: ${self:custom.sqsQueueName}
        ContentBasedDeduplication: true # Assume all message bodies are unique, by design given as an uuid1
        VisibilityTimeout: ${self:custom.editable.timeout}
        RedrivePolicy:
          deadLetterTargetArn: !GetAtt EventQueueDL.Arn
          # The number of times a message is delivered to the source queue before being moved to the dead-letter queue.
          maxReceiveCount: 1


    EventQueueDL: # Messages that fail are put here
      Type: AWS::SQS::Queue
      Properties:
        FifoQueue: true
        QueueName: ${self:custom.sqsQueueDLName}
        ContentBasedDeduplication: true # Assume all message bodies are unique, by design given as an uuid1

plugins:
  - serverless-python-requirements
  - serverless-pseudo-parameters
